{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from skimage import data, exposure, measure\n",
    "from skimage import filters, morphology\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "from math import sqrt\n",
    "from skimage.color import rgb2gray\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def showimg(img):\n",
    "    io.imshow(img)\n",
    "    io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# getFiles gets all the unique files from the given directory path, without the annotations\n",
    "def getFiles(path):\n",
    "    files = os.listdir(path)\n",
    "    all_files = np.empty(0)\n",
    "    for f in files:\n",
    "        [ff, _ ]= f.split('_',1)\n",
    "        all_files = np.append(all_files,os.path.join(path,ff))\n",
    "    return np.unique(all_files)\n",
    "\n",
    "files = getFiles('G:\\Projects\\CADIMI\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# createMask creates a mask used for taking only pixels from the brain, and not from the backgraound\n",
    "def createMask(filename):\n",
    "    filename = filename + '_fl.png'\n",
    "    img = io.imread(filename)\n",
    "    mask = img>0\n",
    "    return mask\n",
    "\n",
    "# reads the images with flair and the answer\n",
    "def readImageFL(filename):\n",
    "    img = io.imread(filename + '_fl.png')\n",
    "    ans = io.imread(filename + '_an.png')\n",
    "    return (img,ans)\n",
    "\n",
    "def readImageT1(filename):\n",
    "    img = io.imread(filename + '_t2.png')\n",
    "    ans = io.imread(filename + '_an.png')\n",
    "    return (img,ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3796529 3796529\n"
     ]
    }
   ],
   "source": [
    "# features receives the image, the mask and the answer and compute the features for that singular image applying the mask\n",
    "def features(img, mask,ans):\n",
    "    f1 = img.copy()\n",
    "    #intensity feature\n",
    "    intensity = f1[mask]\n",
    "    binary_img = img.copy()\n",
    "    binary_img[img>0] = 1\n",
    "    #distance feature\n",
    "    distance = ndimage.distance_transform_edt(morphology.binary_dilation(binary_img,morphology.disk(2)))[mask]\n",
    "    #blobness feature\n",
    "    blobness = ndimage.filters.gaussian_laplace(binary_img, 4)[mask]\n",
    "    ans = ans[mask]\n",
    "    return (np.vstack((intensity, distance, blobness)).T, ans)\n",
    "\n",
    "# runs the feature method for the images, and returns all the features and the answers, this is the dataset\n",
    "def allFeatures(fileNames):\n",
    "    allF = []\n",
    "    allAns = []\n",
    "    for f in fileNames:\n",
    "        mask = createMask(f)\n",
    "        img, ans = readImageFL(f)\n",
    "        f3, ansMasked = features(img,mask,ans)\n",
    "        allF.append(f3)\n",
    "        allAns.append(ansMasked)\n",
    "    return (np.vstack(allF),np.hstack(allAns))\n",
    "\n",
    "f3, ans = allFeatures(files)\n",
    "print len(f3), len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67811 3728718 70523\n",
      "(3728718L, 3L)\n",
      "(70523L, 3L)\n",
      "(67811L, 3L)\n",
      "[0 0 0 ..., 0 0 0] [1 1 1 ..., 1 1 1]\n",
      "(138334L, 3L)\n",
      "138334\n"
     ]
    }
   ],
   "source": [
    "#Balanced the dataset by keeping some random exemples to have closer number between positive and negative samples\n",
    "\n",
    "trueInd = ans > 0\n",
    "noTrue = trueInd.sum()\n",
    "noFalse = len(ans) - noTrue\n",
    "newFalse = int(noTrue * 1.04)\n",
    "print noTrue, noFalse, newFalse\n",
    "\n",
    "newindices = np.random.choice(noFalse, newFalse, replace = False)\n",
    "allFalse = f3[~trueInd]\n",
    "print allFalse.shape\n",
    "\n",
    "newFalseFeatures = allFalse[newindices]\n",
    "print newFalseFeatures.shape\n",
    "\n",
    "true_f = f3[trueInd]\n",
    "print true_f.shape\n",
    "\n",
    "balancedFeatures = np.vstack((newFalseFeatures, true_f))\n",
    "af = np.zeros(newFalse, dtype = int)\n",
    "at = np.ones(noTrue, dtype = int)\n",
    "print af, at\n",
    "balancedAns = np.hstack( [af, at] )\n",
    "print balancedFeatures.shape\n",
    "print noTrue + newFalse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81151511,  0.82329129,  0.74073806,  0.81967035,  0.83767079])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(preprocessing.StandardScaler(), RandomForestClassifier(n_estimators = 100))\n",
    "cross_val_score(clf, balancedFeatures, balancedAns, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81179158,  0.82195009])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(preprocessing.StandardScaler(), SVC(kernel='linear', probability = True))\n",
    "cross_val_score(clf, balancedFeatures, balancedAns, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.78847155,  0.79900529])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(preprocessing.StandardScaler(), tree.DecisionTreeClassifier())\n",
    "cross_val_score(clf, balancedFeatures, balancedAns, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoostClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.86182594,  0.87201359,  0.76101493,  0.85418926,  0.88108147])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = make_pipeline(preprocessing.StandardScaler(), AdaBoostClassifier(n_estimators=100))\n",
    "cross_val_score(clf, balancedFeatures, balancedAns, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
